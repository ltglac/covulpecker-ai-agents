"""
Vulnerability Analysis Pipeline for CoVulPecker.

Orchestrates the Reasoner and Critic agents to perform comprehensive vulnerability analysis.
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
from crewai import Crew, Process

from ..agents import (
    create_reasoner_agent,
    create_analysis_task,
    create_critic_agent,
    create_review_task
)
from ..utils import setup_logger, config

logger = setup_logger(__name__)


class VulnerabilityPipeline:
    """
    Pipeline for orchestrating vulnerability analysis with Reasoner and Critic agents.
    """
    
    def __init__(self):
        """Initialize the vulnerability analysis pipeline."""
        logger.info("Initializing Vulnerability Analysis Pipeline...")
        
        # Create agents
        self.reasoner_agent = create_reasoner_agent()
        self.critic_agent = create_critic_agent()
        
        logger.info("Pipeline initialized successfully")
    
    def analyze(
        self,
        source_code: str,
        context: str = "",
        save_output: bool = True,
        output_filename: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze source code for vulnerabilities using the agent pipeline.
        
        Args:
            source_code: C/C++ source code to analyze
            context: Additional context about the code (optional)
            save_output: Whether to save results to file
            output_filename: Custom output filename (optional)
        
        Returns:
            Dictionary containing analysis and review results
        """
        logger.info("=" * 80)
        logger.info("Starting vulnerability analysis pipeline...")
        logger.info("=" * 80)
        
        try:
            # Phase 1: Reasoner Analysis
            logger.info("\n[Phase 1] Reasoner Agent: Analyzing source code...")
            logger.info("-" * 80)
            
            analysis_task = create_analysis_task(
                agent=self.reasoner_agent,
                source_code=source_code,
                context=context
            )
            
            # Create crew for initial analysis
            analysis_crew = Crew(
                agents=[self.reasoner_agent],
                tasks=[analysis_task],
                process=Process.sequential,
                verbose=True
            )
            
            # Execute analysis
            analysis_result = analysis_crew.kickoff()
            logger.info("\n[Phase 1] Analysis completed")
            logger.info(f"Result: {analysis_result}")
            
            # Phase 2: Critic Review
            logger.info("\n[Phase 2] Critic Agent: Validating analysis...")
            logger.info("-" * 80)
            
            review_task = create_review_task(
                agent=self.critic_agent,
                analysis_report=str(analysis_result),
                source_code=source_code
            )
            
            # Create crew for review
            review_crew = Crew(
                agents=[self.critic_agent],
                tasks=[review_task],
                process=Process.sequential,
                verbose=True
            )
            
            # Execute review
            review_result = review_crew.kickoff()
            logger.info("\n[Phase 2] Review completed")
            logger.info(f"Result: {review_result}")
            
            # Compile final results
            final_results = {
                "timestamp": datetime.now().isoformat(),
                "configuration": config.to_dict(),
                "source_code": source_code,
                "context": context,
                "analysis": {
                    "agent": "Reasoner",
                    "result": str(analysis_result)
                },
                "review": {
                    "agent": "Critic",
                    "result": str(review_result)
                }
            }
            
            # Save results if requested
            if save_output:
                self._save_results(final_results, output_filename)
            
            logger.info("\n" + "=" * 80)
            logger.info("Pipeline execution completed successfully!")
            logger.info("=" * 80)
            
            return final_results
            
        except Exception as e:
            logger.error(f"Pipeline execution failed: {str(e)}", exc_info=True)
            raise
    
    def _save_results(
        self,
        results: Dict[str, Any],
        filename: Optional[str] = None
    ) -> Path:
        """
        Save analysis results to a JSON file.
        
        Args:
            results: Results dictionary to save
            filename: Custom filename (optional)
        
        Returns:
            Path to the saved file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"analysis_{timestamp}.json"
        
        output_path = config.outputs_dir / filename
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"\nResults saved to: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Failed to save results: {str(e)}")
            raise
    
    def analyze_file(
        self,
        file_path: str,
        save_output: bool = True
    ) -> Dict[str, Any]:
        """
        Analyze a source code file for vulnerabilities.
        
        Args:
            file_path: Path to the source code file
            save_output: Whether to save results to file
        
        Returns:
            Dictionary containing analysis and review results
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        logger.info(f"Reading source code from: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            source_code = f.read()
        
        context = f"File: {file_path.name}"
        output_filename = f"analysis_{file_path.stem}.json"
        
        return self.analyze(
            source_code=source_code,
            context=context,
            save_output=save_output,
            output_filename=output_filename
        )
